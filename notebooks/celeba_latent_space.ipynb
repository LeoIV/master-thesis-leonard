{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "vae_gan_celeba = keras.models.load_model(\"/Users/leo/Downloads/vae_gan_celeba_128.h5\")\n",
    "vae_gan_celeba_decoder = vae_gan_celeba.layers[-1]\n",
    "vae_gan_celeba_encoder = keras.Model(vae_gan_celeba.layers[0].input, vae_gan_celeba.layers[-2].output)\n",
    "\n",
    "vlae_gan_celeba = keras.models.load_model(\"/Users/leo/Downloads/vlae_gan_128_celeba.h5\")\n",
    "vlae_gan_celeba_decoder = vlae_gan_celeba.layers[-1]\n",
    "vlae_gan_celeba_encoder = keras.Model(vlae_gan_celeba.layers[0].input, (vlae_gan_celeba.layers[-4].output, vlae_gan_celeba.layers[-3].output, vlae_gan_celeba.layers[-2].output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import trange, tqdm\n",
    "\n",
    "from models.VLAE import VLAE\n",
    "from models.VAE import VAE\n",
    "\n",
    "vlae_celeba = VLAE(input_dim=(128,128,3), log_dir='',\n",
    "                         inf0_kernels_strides_featuremaps=[(4, 2, 32), (4, 1, 32)],\n",
    "                         inf1_kernels_strides_featuremaps=[(4, 2, 64), (4, 1, 64)],\n",
    "                         ladder0_kernels_strides_featuremaps=[(4, 2, 128), (4, 1, 128)],\n",
    "                         ladder1_kernels_strides_featuremaps=[(4, 2, 256), (4, 1, 256)],\n",
    "                         ladder2_kernels_strides_featuremaps=[(4, 2, 256), (4, 2, 512), (4, 1, 512), (4, 1, 512)],\n",
    "                         gen2_num_units=[256, 512],\n",
    "                         gen1_num_units=[512, 1024],\n",
    "                         gen0_kernels_strides_featuremaps=[(4, 1, 1024), (4, 2, 512), (4, 2, 256), (4, 2, 128),\n",
    "                                                           (4, 2, 64), (4, 1, 3)],\n",
    "                         kernel_visualization_layer=1, num_samples=5,\n",
    "                         feature_map_layers=[], inner_activation='ReLU',\n",
    "                         decay_rate=.0, feature_map_reduction_factor=1,\n",
    "                         z_dims=[2,2,2], dropout_rate=.0, use_dropout=False,\n",
    "                         use_batch_norm=True)\n",
    "vlae_celeba.load_weights('/Users/leo/Downloads/vlae_128_celeba.h5')\n",
    "\n",
    "vae_celeba = VAE(input_dim=(128,128,3), encoder_conv_filters=[32, 64, 128, 256, 512],\n",
    "                        encoder_conv_kernel_size=[4, 4, 4, 4, 4], encoder_conv_strides=[2, 2, 2, 2, 1],\n",
    "                        decoder_conv_t_filters=[512, 256, 128, 3],\n",
    "                        decoder_conv_t_kernel_size=[4, 4, 4, 4, 4],\n",
    "                        decoder_conv_t_strides=[2, 2, 2, 2, 1], log_dir='', z_dims=[8],\n",
    "                        kernel_visualization_layer=1,\n",
    "                        feature_map_layers=[], use_batch_norm=False,\n",
    "                        use_dropout=False,\n",
    "                        decay_rate=.0, num_samples=5,\n",
    "                        feature_map_reduction_factor=1,\n",
    "                        inner_activation='ReLU', dropout_rate=.0)\n",
    "\n",
    "vae_celeba.load_weights('/Users/leo/Downloads/vae_128_celeba.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['image_id', '5_o_Clock_Shadow', 'Arched_Eyebrows', 'Attractive', 'Bags_Under_Eyes', 'Bald', 'Bangs', 'Big_Lips', 'Big_Nose', 'Black_Hair', 'Blond_Hair', 'Blurry', 'Brown_Hair', 'Bushy_Eyebrows', 'Chubby', 'Double_Chin', 'Eyeglasses', 'Goatee', 'Gray_Hair', 'Heavy_Makeup', 'High_Cheekbones', 'Male', 'Mouth_Slightly_Open', 'Mustache', 'Narrow_Eyes', 'No_Beard', 'Oval_Face', 'Pale_Skin', 'Pointy_Nose', 'Receding_Hairline', 'Rosy_Cheeks', 'Sideburns', 'Smiling', 'Straight_Hair', 'Wavy_Hair', 'Wearing_Earrings', 'Wearing_Hat', 'Wearing_Lipstick', 'Wearing_Necklace', 'Wearing_Necktie', 'Young']\n"
     ]
    }
   ],
   "source": [
    "import os, csv\n",
    "\n",
    "celeba_attrs = {}\n",
    "celeba_headers = []\n",
    "\n",
    "with open(os.path.join('/Users/leo/Downloads/29561_37705_bundle_archive/list_attr_celeba.csv'), newline='') as csvfile:\n",
    "    spamreader = csv.reader(csvfile, delimiter=',', quotechar=\"'\")\n",
    "    for i, row in enumerate(spamreader):\n",
    "        if i == 0:\n",
    "            print(row)\n",
    "            for header in row:\n",
    "                celeba_attrs.setdefault(header, [])\n",
    "                celeba_headers.append(header)\n",
    "        else:\n",
    "            for j, cell in enumerate(row):\n",
    "                celeba_attrs[celeba_headers[j]].append(cell)\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "from skimage.io import imread\n",
    "\n",
    "\n",
    "\n",
    "def image_generator(directory, idxs, batch_size = 64):\n",
    "    files = os.listdir(directory)\n",
    "    idxs = np.array(idxs)\n",
    "    files = np.array(celeba_attrs['image_id'])[idxs].flatten()\n",
    "    global image_ids \n",
    "    image_ids = np.array(celeba_attrs['5_o_Clock_Shadow'], dtype=np.float32)[idxs]\n",
    "    \n",
    "    num_batch = 0\n",
    "    while True:\n",
    "        # Select files (paths/indices) for the batch\n",
    "        batch_paths  = files[num_batch*batch_size:(num_batch+1)*batch_size]\n",
    "        batch_input  = []\n",
    "          \n",
    "        # Read in each input, perform preprocessing and get labels\n",
    "        for input_path in batch_paths:\n",
    "            img = np.array(Image.open(os.path.join(directory, input_path)).resize((128,128))) / 255.0\n",
    "            \n",
    "            # input = preprocess_input(image=input)\n",
    "            batch_input += [ img ]\n",
    "        # Return a tuple of (input, output) to feed the network\n",
    "        batch_x = np.array( batch_input )\n",
    "        num_batch += 1\n",
    "        \n",
    "        yield batch_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(142)\n",
    "\n",
    "all_ids = np.arange(0, len(celeba_attrs['image_id']))\n",
    "np.random.shuffle(all_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted vae\n",
      "predicted vae gan\n",
      "predicted vlae\n",
      "predicted vlae gan\n"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "steps = 100\n",
    "marker_size=10\n",
    "\n",
    "all_generator = image_generator('/Users/leo/Downloads/29561_37705_bundle_archive/img_align_celeba/img_align_celeba',all_ids, batch_size)\n",
    "vae_preds = vae_celeba.encoder.predict_generator(all_generator, steps = steps)\n",
    "print(\"predicted vae\")\n",
    "all_generator = image_generator('/Users/leo/Downloads/29561_37705_bundle_archive/img_align_celeba/img_align_celeba',all_ids, batch_size)\n",
    "vae_gan_preds = vae_gan_celeba_encoder.predict_generator(all_generator, steps = steps)\n",
    "print(\"predicted vae gan\")\n",
    "all_generator = image_generator('/Users/leo/Downloads/29561_37705_bundle_archive/img_align_celeba/img_align_celeba',all_ids, batch_size)\n",
    "vlae_preds = vlae_celeba.encoder.predict_generator(all_generator, steps = steps)\n",
    "print(\"predicted vlae\")\n",
    "all_generator = image_generator('/Users/leo/Downloads/29561_37705_bundle_archive/img_align_celeba/img_align_celeba',all_ids, batch_size)\n",
    "vlae_gan_preds = vlae_gan_celeba_encoder.predict_generator(all_generator, steps = steps)\n",
    "print(\"predicted vlae gan\")\n",
    "num_preds = steps*batch_size\n",
    "vae_mus_embedded = TSNE().fit_transform(vae_preds)\n",
    "vae_gan_mus_embedded = TSNE().fit_transform(vae_gan_preds)\n",
    "vlae_mus_embedded = [TSNE().fit_transform(p) for p in vlae_preds]\n",
    "vlae_gan_mus_embedded = [TSNE().fit_transform(p) for p in vlae_gan_preds]\n",
    "\n",
    "for name in celeba_attrs.keys():\n",
    "    print(name)\n",
    "    if name == 'image_id':\n",
    "        continue\n",
    "    idxs = np.copy(np.array(celeba_attrs[name], dtype=np.float32))\n",
    "    \n",
    "    idxs = idxs[all_ids]\n",
    "    attr_values = np.array(idxs[:num_preds], dtype=np.float32)\n",
    "    attr_values += 1.0\n",
    "    attr_values /= 2.0\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    off_attribute_idxs = np.where(attr_values==0.0)\n",
    "    on_attribute_idxs = np.where(attr_values==1.0)\n",
    "    ax.scatter(vae_mus_embedded[off_attribute_idxs, 0], vae_mus_embedded[off_attribute_idxs, 1], s=marker_size, alpha=0.5, c = 'r', label=\"Not {}\".format(' '.join(name.split('_'))))    \n",
    "    ax.scatter(vae_mus_embedded[on_attribute_idxs, 0], vae_mus_embedded[on_attribute_idxs, 1], s=marker_size, alpha=0.5, c = 'g', label=\"{}\".format(' '.join(name.split('_'))))        \n",
    "    ax.legend()\n",
    "    fig.suptitle('VAE')\n",
    "    fig.savefig('vae_celeba_{}'.format(name))\n",
    "    plt.show(fig)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(4, 4))\n",
    "    off_attribute_idxs = np.where(attr_values==0.0)\n",
    "    on_attribute_idxs = np.where(attr_values==1.0)\n",
    "    ax.scatter(vae_gan_mus_embedded[off_attribute_idxs, 0], vae_gan_mus_embedded[off_attribute_idxs, 1], s=marker_size, alpha=0.5, c = 'r', label=\"Not {}\".format(' '.join(name.split('_'))))    \n",
    "    ax.scatter(vae_gan_mus_embedded[on_attribute_idxs, 0], vae_gan_mus_embedded[on_attribute_idxs, 1], s=marker_size, alpha=0.5, c = 'g', label=\"{}\".format(' '.join(name.split('_'))))        \n",
    "    ax.legend()\n",
    "    fig.suptitle('VAE GAN')\n",
    "    fig.savefig('vae_gan_celeba_{}'.format(name))\n",
    "    plt.show(fig)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    fig, axs = plt.subplots(ncols=3,nrows=1,figsize=(12,4))\n",
    "    for dim in range(3):\n",
    "        axs[dim].scatter(vlae_mus_embedded[dim][off_attribute_idxs, 0], vlae_mus_embedded[dim][off_attribute_idxs, 1], s=marker_size, alpha=0.5, c = 'r', label=\"Not {}\".format(' '.join(name.split('_'))))\n",
    "        axs[dim].scatter(vlae_mus_embedded[dim][on_attribute_idxs, 0], vlae_mus_embedded[dim][on_attribute_idxs, 1], s=marker_size, alpha=0.5, c = 'g', label=\"{}\".format(' '.join(name.split('_'))))            \n",
    "        axs[dim].legend()\n",
    "    fig.suptitle('VLAE') \n",
    "    fig.savefig('vlae_celeba_{}'.format(name))\n",
    "    plt.show(fig)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    fig, axs = plt.subplots(ncols=3,nrows=1,figsize=(12,4))\n",
    "    for dim in range(3):\n",
    "        axs[dim].scatter(vlae_gan_mus_embedded[dim][off_attribute_idxs, 0], vlae_gan_mus_embedded[dim][off_attribute_idxs, 1], s=marker_size, alpha=0.5, c = 'r', label=\"Not {}\".format(' '.join(name.split('_'))))\n",
    "        axs[dim].scatter(vlae_gan_mus_embedded[dim][on_attribute_idxs, 0], vlae_gan_mus_embedded[dim][on_attribute_idxs, 1], s=marker_size, alpha=0.5, c = 'g', label=\"{}\".format(' '.join(name.split('_'))))            \n",
    "        axs[dim].legend()\n",
    "    fig.suptitle('VLAE GAN')  \n",
    "    fig.savefig('vlae_gan_celeba_{}'.format(name))\n",
    "    plt.show(fig)\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "from vis.backprop_modifiers import get\n",
    "from vis.input_modifiers import Jitter\n",
    "from vis.losses import Loss\n",
    "from vis.regularizers import LPNorm, TotalVariation\n",
    "\n",
    "from models.VLAE import VLAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "WARNING:tensorflow:From /Users/leo/.local/share/virtualenvs/Master_Thesis-iDondhVg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leo/.local/share/virtualenvs/Master_Thesis-iDondhVg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leo/.local/share/virtualenvs/Master_Thesis-iDondhVg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leo/.local/share/virtualenvs/Master_Thesis-iDondhVg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leo/.local/share/virtualenvs/Master_Thesis-iDondhVg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leo/.local/share/virtualenvs/Master_Thesis-iDondhVg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leo/.local/share/virtualenvs/Master_Thesis-iDondhVg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leo/.local/share/virtualenvs/Master_Thesis-iDondhVg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leo/.local/share/virtualenvs/Master_Thesis-iDondhVg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leo/.local/share/virtualenvs/Master_Thesis-iDondhVg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leo/.local/share/virtualenvs/Master_Thesis-iDondhVg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /Users/leo/.local/share/virtualenvs/Master_Thesis-iDondhVg/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4115: The name tf.random_normal is deprecated. Please use tf.random.normal instead.\n",
      "\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "model = VLAE(input_dim=(28,28,1), log_dir=\"tralala\", kernel_visualization_layer=1, num_samples=1, feature_map_layers=[1], inner_activation=\"ReLU\", decay_rate=0.3, feature_map_reduction_factor=2, z_dims=[2,2,2], dropout_rate=0.3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "model.load_weights(\"/Users/leo/Documents/Tesla/alexnet-vae-no-padding/logs_vlae_mnist_smaller_model_20-03-2020/weights/weights.h5\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "outputs": [],
   "source": [
    "class MyActivationMaximization(Loss):\n",
    "    \"\"\"A loss function that maximizes the activation of a set of filters within a particular layer.\n",
    "    Typically this loss is used to ask the reverse question - What kind of input image would increase the networks\n",
    "    confidence, for say, dog class. This helps determine what the network might be internalizing as being the 'dog'\n",
    "    image space.\n",
    "    One might also use this to generate an input image that maximizes both 'dog' and 'human' outputs on the final\n",
    "    `keras.layers.Dense` layer.\n",
    "    \"\"\"\n",
    "    def __init__(self, layers, desired_mean = (0.0, 0.0)):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            layer: The keras layer whose filters need to be maximized. This can either be a convolutional layer\n",
    "                or a dense layer.\n",
    "            filter_indices: filter indices within the layer to be maximized.\n",
    "                For `keras.layers.Dense` layer, `filter_idx` is interpreted as the output index.\n",
    "                If you are optimizing final `keras.layers.Dense` layer to maximize class output, you tend to get\n",
    "                better results with 'linear' activation as opposed to 'softmax'. This is because 'softmax'\n",
    "                output can be maximized by minimizing scores for other classes.\n",
    "        \"\"\"\n",
    "        super(MyActivationMaximization, self).__init__()\n",
    "        self.desired_mean = desired_mean\n",
    "        self.name = \"ActivationMax Loss\"\n",
    "        self.layers = layers\n",
    "\n",
    "    def build_loss(self):\n",
    "\n",
    "        # For all other layers it is 4\n",
    "        #is_dense = K.ndim(layer_output) == 2\n",
    "\n",
    "        loss = 0.\n",
    "        \n",
    "        mu_layers = [l for l in self.layers if \"mu\" in l.name]\n",
    "        log_var_layers = [l for l in self.layers if \"log_var\" in l.name]\n",
    "        \n",
    "        for lvl in log_var_layers:\n",
    "            loss += K.mean(K.square(lvl.output-1.0))\n",
    "            \n",
    "        for ml in mu_layers:\n",
    "            loss += K.mean(K.square(ml.output))\n",
    "        \n",
    "        return loss\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "outputs": [],
   "source": [
    "def my_visualize_activation(model, layer_idx, filter_indices=None, wrt_tensor=None,\n",
    "                         seed_input=None, input_range=(0, 255),\n",
    "                         backprop_modifier=None, grad_modifier=None,\n",
    "                         act_max_weight=1, lp_norm_weight=10, tv_weight=10, desired_mean=0.0,\n",
    "                         **optimizer_params):\n",
    "    if backprop_modifier is not None:\n",
    "        modifier_fn = get(backprop_modifier)\n",
    "        model = modifier_fn(model)\n",
    "\n",
    "    losses = [\n",
    "        (MyActivationMaximization(model.layers, desired_mean), act_max_weight),\n",
    "        (LPNorm(model.input), lp_norm_weight),\n",
    "        (TotalVariation(model.input), tv_weight)\n",
    "    ]\n",
    "\n",
    "    # Add grad_filter to optimizer_params.\n",
    "    optimizer_params = utils.add_defaults_to_kwargs({\n",
    "        'grad_modifier': grad_modifier\n",
    "    }, **optimizer_params)\n",
    "    \n",
    "\n",
    "    return visualize_activation_with_losses(model.input, losses, wrt_tensor,\n",
    "                                            seed_input, input_range, **optimizer_params)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 28, 28, 1)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 13, 13, 32)   544         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 13, 13, 32)   128         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_1 (ReLU)                  (None, 13, 13, 32)   0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 5, 5, 64)     32832       re_lu_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 5, 5, 64)     256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_2 (ReLU)                  (None, 5, 5, 64)     0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 5, 5, 512)    33280       re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 5, 5, 512)    2048        dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_4 (ReLU)                  (None, 5, 5, 512)    0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 5, 5, 512)    262656      re_lu_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 5, 5, 512)    2048        dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_5 (ReLU)                  (None, 5, 5, 512)    0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 5, 5, 512)    33280       re_lu_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 5, 5, 512)    262656      re_lu_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 5, 5, 512)    2048        dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 5, 5, 512)    2048        dense_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_6 (ReLU)                  (None, 5, 5, 512)    0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_8 (ReLU)                  (None, 5, 5, 512)    0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 13, 13, 32)   544         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 5, 5, 512)    262656      re_lu_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Dense)                 (None, 5, 5, 512)    262656      re_lu_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 13, 13, 32)   128         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 5, 5, 512)    2048        dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 5, 5, 512)    2048        dense_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_3 (ReLU)                  (None, 13, 13, 32)   0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_7 (ReLU)                  (None, 5, 5, 512)    0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "re_lu_9 (ReLU)                  (None, 5, 5, 512)    0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 5408)         0           re_lu_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 12800)        0           re_lu_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 12800)        0           re_lu_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "mu_1 (Dense)                    (None, 2)            10818       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_var_1 (Dense)               (None, 2)            10818       flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mu_2 (Dense)                    (None, 2)            25602       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_var_2 (Dense)               (None, 2)            25602       flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "mu_3 (Dense)                    (None, 2)            25602       flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "log_var_3 (Dense)               (None, 2)            25602       flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_1_latent (Lambda)             (None, 2)            0           mu_1[0][0]                       \n",
      "                                                                 log_var_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_2_latent (Lambda)             (None, 2)            0           mu_2[0][0]                       \n",
      "                                                                 log_var_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "z_3_latent (Lambda)             (None, 2)            0           mu_3[0][0]                       \n",
      "                                                                 log_var_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,287,948\n",
      "Trainable params: 1,281,548\n",
      "Non-trainable params: 6,400\n",
      "__________________________________________________________________________________________________\n",
      "Iteration: 1, named_losses: [('ActivationMax Loss', 84.80316)], overall loss: 84.80316162109375\n",
      "Iteration: 2, named_losses: [('ActivationMax Loss', 15326.306)], overall loss: 15326.3056640625\n",
      "Iteration: 3, named_losses: [('ActivationMax Loss', 8393.043)], overall loss: 8393.04296875\n",
      "Iteration: 4, named_losses: [('ActivationMax Loss', 4186.4062)], overall loss: 4186.40625\n",
      "Iteration: 5, named_losses: [('ActivationMax Loss', 9868.592)], overall loss: 9868.591796875\n",
      "Iteration: 6, named_losses: [('ActivationMax Loss', 24168.459)], overall loss: 24168.458984375\n",
      "Iteration: 7, named_losses: [('ActivationMax Loss', 43296.68)], overall loss: 43296.6796875\n",
      "Iteration: 8, named_losses: [('ActivationMax Loss', 10184.638)], overall loss: 10184.6376953125\n",
      "Iteration: 9, named_losses: [('ActivationMax Loss', 9295.628)], overall loss: 9295.6279296875\n",
      "Iteration: 10, named_losses: [('ActivationMax Loss', 4600.389)], overall loss: 4600.38916015625\n",
      "Iteration: 11, named_losses: [('ActivationMax Loss', 3371.1272)], overall loss: 3371.127197265625\n",
      "Iteration: 12, named_losses: [('ActivationMax Loss', 12052.25)], overall loss: 12052.25\n",
      "Iteration: 13, named_losses: [('ActivationMax Loss', 953.4423)], overall loss: 953.4423217773438\n",
      "Iteration: 14, named_losses: [('ActivationMax Loss', 1018.7119)], overall loss: 1018.7119140625\n",
      "Iteration: 15, named_losses: [('ActivationMax Loss', 2053.6196)], overall loss: 2053.61962890625\n",
      "Iteration: 16, named_losses: [('ActivationMax Loss', 607.111)], overall loss: 607.1110229492188\n",
      "Iteration: 17, named_losses: [('ActivationMax Loss', 12421.382)], overall loss: 12421.3818359375\n",
      "Iteration: 18, named_losses: [('ActivationMax Loss', 5695.3423)], overall loss: 5695.34228515625\n",
      "Iteration: 19, named_losses: [('ActivationMax Loss', 10664.846)], overall loss: 10664.845703125\n",
      "Iteration: 20, named_losses: [('ActivationMax Loss', 2506.6948)], overall loss: 2506.69482421875\n",
      "Iteration: 21, named_losses: [('ActivationMax Loss', 2631.8418)], overall loss: 2631.841796875\n",
      "Iteration: 22, named_losses: [('ActivationMax Loss', 970.2453)], overall loss: 970.2453002929688\n",
      "Iteration: 23, named_losses: [('ActivationMax Loss', 8143.8745)], overall loss: 8143.87451171875\n",
      "Iteration: 24, named_losses: [('ActivationMax Loss', 2380.981)], overall loss: 2380.98095703125\n",
      "Iteration: 25, named_losses: [('ActivationMax Loss', 6384.0967)], overall loss: 6384.0966796875\n",
      "Iteration: 26, named_losses: [('ActivationMax Loss', 3045.925)], overall loss: 3045.925048828125\n",
      "Iteration: 27, named_losses: [('ActivationMax Loss', 3288.6165)], overall loss: 3288.616455078125\n",
      "Iteration: 28, named_losses: [('ActivationMax Loss', 1652.6171)], overall loss: 1652.6170654296875\n",
      "Iteration: 29, named_losses: [('ActivationMax Loss', 681.60254)], overall loss: 681.6025390625\n",
      "Iteration: 30, named_losses: [('ActivationMax Loss', 1086.4601)], overall loss: 1086.4600830078125\n",
      "Iteration: 31, named_losses: [('ActivationMax Loss', 2067.3813)], overall loss: 2067.38134765625\n",
      "Iteration: 32, named_losses: [('ActivationMax Loss', 5044.096)], overall loss: 5044.09619140625\n",
      "Iteration: 33, named_losses: [('ActivationMax Loss', 2784.3635)], overall loss: 2784.363525390625\n",
      "Iteration: 34, named_losses: [('ActivationMax Loss', 5582.7847)], overall loss: 5582.78466796875\n",
      "Iteration: 35, named_losses: [('ActivationMax Loss', 4081.6768)], overall loss: 4081.6767578125\n",
      "Iteration: 36, named_losses: [('ActivationMax Loss', 4187.632)], overall loss: 4187.6318359375\n",
      "Iteration: 37, named_losses: [('ActivationMax Loss', 690.6173)], overall loss: 690.6173095703125\n",
      "Iteration: 38, named_losses: [('ActivationMax Loss', 4003.8572)], overall loss: 4003.857177734375\n",
      "Iteration: 39, named_losses: [('ActivationMax Loss', 5878.217)], overall loss: 5878.216796875\n",
      "Iteration: 40, named_losses: [('ActivationMax Loss', 7185.7134)], overall loss: 7185.71337890625\n",
      "Iteration: 41, named_losses: [('ActivationMax Loss', 18047.639)], overall loss: 18047.638671875\n",
      "Iteration: 42, named_losses: [('ActivationMax Loss', 2326.9653)], overall loss: 2326.96533203125\n",
      "Iteration: 43, named_losses: [('ActivationMax Loss', 2716.0078)], overall loss: 2716.0078125\n",
      "Iteration: 44, named_losses: [('ActivationMax Loss', 514.59344)], overall loss: 514.5934448242188\n",
      "Iteration: 45, named_losses: [('ActivationMax Loss', 2941.6257)], overall loss: 2941.625732421875\n",
      "Iteration: 46, named_losses: [('ActivationMax Loss', 8894.273)], overall loss: 8894.2734375\n",
      "Iteration: 47, named_losses: [('ActivationMax Loss', 1687.0961)], overall loss: 1687.0960693359375\n",
      "Iteration: 48, named_losses: [('ActivationMax Loss', 4182.2617)], overall loss: 4182.26171875\n",
      "Iteration: 49, named_losses: [('ActivationMax Loss', 2860.5288)], overall loss: 2860.52880859375\n",
      "Iteration: 50, named_losses: [('ActivationMax Loss', 502.4027)], overall loss: 502.4027099609375\n",
      "Iteration: 51, named_losses: [('ActivationMax Loss', 1266.6394)], overall loss: 1266.639404296875\n",
      "Iteration: 52, named_losses: [('ActivationMax Loss', 19950.387)], overall loss: 19950.38671875\n",
      "Iteration: 53, named_losses: [('ActivationMax Loss', 1763.0328)], overall loss: 1763.0328369140625\n",
      "Iteration: 54, named_losses: [('ActivationMax Loss', 1160.0682)], overall loss: 1160.0682373046875\n",
      "Iteration: 55, named_losses: [('ActivationMax Loss', 16837.986)], overall loss: 16837.986328125\n",
      "Iteration: 56, named_losses: [('ActivationMax Loss', 804.0823)], overall loss: 804.082275390625\n",
      "Iteration: 57, named_losses: [('ActivationMax Loss', 2094.0847)], overall loss: 2094.084716796875\n",
      "Iteration: 58, named_losses: [('ActivationMax Loss', 2867.0723)], overall loss: 2867.072265625\n",
      "Iteration: 59, named_losses: [('ActivationMax Loss', 10127.086)], overall loss: 10127.0859375\n",
      "Iteration: 60, named_losses: [('ActivationMax Loss', 2735.9285)], overall loss: 2735.928466796875\n",
      "Iteration: 61, named_losses: [('ActivationMax Loss', 3005.9167)], overall loss: 3005.916748046875\n",
      "Iteration: 62, named_losses: [('ActivationMax Loss', 6049.117)], overall loss: 6049.1171875\n",
      "Iteration: 63, named_losses: [('ActivationMax Loss', 548.26666)], overall loss: 548.2666625976562\n",
      "Iteration: 64, named_losses: [('ActivationMax Loss', 11889.766)], overall loss: 11889.765625\n",
      "Iteration: 65, named_losses: [('ActivationMax Loss', 7307.7046)], overall loss: 7307.70458984375\n",
      "Iteration: 66, named_losses: [('ActivationMax Loss', 2086.7979)], overall loss: 2086.7978515625\n",
      "Iteration: 67, named_losses: [('ActivationMax Loss', 3130.44)], overall loss: 3130.43994140625\n",
      "Iteration: 68, named_losses: [('ActivationMax Loss', 11921.694)], overall loss: 11921.6943359375\n",
      "Iteration: 69, named_losses: [('ActivationMax Loss', 2642.992)], overall loss: 2642.991943359375\n",
      "Iteration: 70, named_losses: [('ActivationMax Loss', 4837.5576)], overall loss: 4837.5576171875\n",
      "Iteration: 71, named_losses: [('ActivationMax Loss', 9303.625)], overall loss: 9303.625\n",
      "Iteration: 72, named_losses: [('ActivationMax Loss', 3423.7056)], overall loss: 3423.70556640625\n",
      "Iteration: 73, named_losses: [('ActivationMax Loss', 3598.6985)], overall loss: 3598.698486328125\n",
      "Iteration: 74, named_losses: [('ActivationMax Loss', 18252.143)], overall loss: 18252.142578125\n",
      "Iteration: 75, named_losses: [('ActivationMax Loss', 9424.015)], overall loss: 9424.0146484375\n",
      "Iteration: 76, named_losses: [('ActivationMax Loss', 15108.955)], overall loss: 15108.955078125\n",
      "Iteration: 77, named_losses: [('ActivationMax Loss', 1228.4816)], overall loss: 1228.4815673828125\n",
      "Iteration: 78, named_losses: [('ActivationMax Loss', 1459.8966)], overall loss: 1459.8966064453125\n",
      "Iteration: 79, named_losses: [('ActivationMax Loss', 1992.835)], overall loss: 1992.8349609375\n",
      "Iteration: 80, named_losses: [('ActivationMax Loss', 11189.507)], overall loss: 11189.5068359375\n",
      "Iteration: 81, named_losses: [('ActivationMax Loss', 5060.494)], overall loss: 5060.494140625\n",
      "Iteration: 82, named_losses: [('ActivationMax Loss', 1077.6948)], overall loss: 1077.69482421875\n",
      "Iteration: 83, named_losses: [('ActivationMax Loss', 2751.4858)], overall loss: 2751.48583984375\n",
      "Iteration: 84, named_losses: [('ActivationMax Loss', 2029.7032)], overall loss: 2029.7032470703125\n",
      "Iteration: 85, named_losses: [('ActivationMax Loss', 1312.5094)], overall loss: 1312.5093994140625\n",
      "Iteration: 86, named_losses: [('ActivationMax Loss', 2915.549)], overall loss: 2915.549072265625\n",
      "Iteration: 87, named_losses: [('ActivationMax Loss', 3443.0896)], overall loss: 3443.089599609375\n",
      "Iteration: 88, named_losses: [('ActivationMax Loss', 1447.6234)], overall loss: 1447.6234130859375\n",
      "Iteration: 89, named_losses: [('ActivationMax Loss', 5468.4683)], overall loss: 5468.46826171875\n",
      "Iteration: 90, named_losses: [('ActivationMax Loss', 2075.4695)], overall loss: 2075.469482421875\n",
      "Iteration: 91, named_losses: [('ActivationMax Loss', 2293.9016)], overall loss: 2293.901611328125\n",
      "Iteration: 92, named_losses: [('ActivationMax Loss', 1516.082)], overall loss: 1516.08203125\n",
      "Iteration: 93, named_losses: [('ActivationMax Loss', 3804.884)], overall loss: 3804.884033203125\n",
      "Iteration: 94, named_losses: [('ActivationMax Loss', 10800.956)], overall loss: 10800.9560546875\n",
      "Iteration: 95, named_losses: [('ActivationMax Loss', 2101.1785)], overall loss: 2101.178466796875\n",
      "Iteration: 96, named_losses: [('ActivationMax Loss', 6222.085)], overall loss: 6222.0849609375\n",
      "Iteration: 97, named_losses: [('ActivationMax Loss', 4235.744)], overall loss: 4235.744140625\n",
      "Iteration: 98, named_losses: [('ActivationMax Loss', 9708.977)], overall loss: 9708.9765625\n",
      "Iteration: 99, named_losses: [('ActivationMax Loss', 5210.3345)], overall loss: 5210.33447265625\n",
      "Iteration: 100, named_losses: [('ActivationMax Loss', 2589.1843)], overall loss: 2589.184326171875\n",
      "Iteration: 101, named_losses: [('ActivationMax Loss', 1067.899)], overall loss: 1067.8990478515625\n",
      "Iteration: 102, named_losses: [('ActivationMax Loss', 1286.181)], overall loss: 1286.1810302734375\n",
      "Iteration: 103, named_losses: [('ActivationMax Loss', 1815.9003)], overall loss: 1815.9002685546875\n",
      "Iteration: 104, named_losses: [('ActivationMax Loss', 4071.2268)], overall loss: 4071.226806640625\n",
      "Iteration: 105, named_losses: [('ActivationMax Loss', 3299.5017)], overall loss: 3299.501708984375\n",
      "Iteration: 106, named_losses: [('ActivationMax Loss', 3793.5078)], overall loss: 3793.5078125\n",
      "Iteration: 107, named_losses: [('ActivationMax Loss', 4095.293)], overall loss: 4095.29296875\n",
      "Iteration: 108, named_losses: [('ActivationMax Loss', 3357.7769)], overall loss: 3357.77685546875\n",
      "Iteration: 109, named_losses: [('ActivationMax Loss', 5572.197)], overall loss: 5572.19677734375\n",
      "Iteration: 110, named_losses: [('ActivationMax Loss', 1547.4937)], overall loss: 1547.49365234375\n",
      "Iteration: 111, named_losses: [('ActivationMax Loss', 2834.4385)], overall loss: 2834.4384765625\n",
      "Iteration: 112, named_losses: [('ActivationMax Loss', 4406.996)], overall loss: 4406.99609375\n",
      "Iteration: 113, named_losses: [('ActivationMax Loss', 1208.8597)], overall loss: 1208.8597412109375\n",
      "Iteration: 114, named_losses: [('ActivationMax Loss', 5277.9404)], overall loss: 5277.9404296875\n",
      "Iteration: 115, named_losses: [('ActivationMax Loss', 9661.889)], overall loss: 9661.888671875\n",
      "Iteration: 116, named_losses: [('ActivationMax Loss', 2657.815)], overall loss: 2657.81494140625\n",
      "Iteration: 117, named_losses: [('ActivationMax Loss', 8849.125)], overall loss: 8849.125\n",
      "Iteration: 118, named_losses: [('ActivationMax Loss', 5282.9746)], overall loss: 5282.974609375\n",
      "Iteration: 119, named_losses: [('ActivationMax Loss', 958.6718)], overall loss: 958.6718139648438\n",
      "Iteration: 120, named_losses: [('ActivationMax Loss', 6241.6694)], overall loss: 6241.66943359375\n",
      "Iteration: 121, named_losses: [('ActivationMax Loss', 2073.141)], overall loss: 2073.14111328125\n",
      "Iteration: 122, named_losses: [('ActivationMax Loss', 838.20874)], overall loss: 838.208740234375\n",
      "Iteration: 123, named_losses: [('ActivationMax Loss', 1671.9631)], overall loss: 1671.963134765625\n",
      "Iteration: 124, named_losses: [('ActivationMax Loss', 1463.4862)], overall loss: 1463.4862060546875\n",
      "Iteration: 125, named_losses: [('ActivationMax Loss', 11545.296)], overall loss: 11545.2958984375\n",
      "Iteration: 126, named_losses: [('ActivationMax Loss', 2374.5325)], overall loss: 2374.532470703125\n",
      "Iteration: 127, named_losses: [('ActivationMax Loss', 860.8457)], overall loss: 860.845703125\n",
      "Iteration: 128, named_losses: [('ActivationMax Loss', 8406.291)], overall loss: 8406.291015625\n",
      "Iteration: 129, named_losses: [('ActivationMax Loss', 2261.0542)], overall loss: 2261.05419921875\n",
      "Iteration: 130, named_losses: [('ActivationMax Loss', 3585.2158)], overall loss: 3585.2158203125\n",
      "Iteration: 131, named_losses: [('ActivationMax Loss', 1745.9103)], overall loss: 1745.9102783203125\n",
      "Iteration: 132, named_losses: [('ActivationMax Loss', 6079.4966)], overall loss: 6079.49658203125\n",
      "Iteration: 133, named_losses: [('ActivationMax Loss', 1265.8124)], overall loss: 1265.8123779296875\n",
      "Iteration: 134, named_losses: [('ActivationMax Loss', 4317.483)], overall loss: 4317.48291015625\n",
      "Iteration: 135, named_losses: [('ActivationMax Loss', 7133.527)], overall loss: 7133.52685546875\n",
      "Iteration: 136, named_losses: [('ActivationMax Loss', 1373.7078)], overall loss: 1373.707763671875\n",
      "Iteration: 137, named_losses: [('ActivationMax Loss', 12503.654)], overall loss: 12503.654296875\n",
      "Iteration: 138, named_losses: [('ActivationMax Loss', 16484.795)], overall loss: 16484.794921875\n",
      "Iteration: 139, named_losses: [('ActivationMax Loss', 17738.877)], overall loss: 17738.876953125\n",
      "Iteration: 140, named_losses: [('ActivationMax Loss', 3350.0613)], overall loss: 3350.061279296875\n",
      "Iteration: 141, named_losses: [('ActivationMax Loss', 1680.6195)], overall loss: 1680.6195068359375\n",
      "Iteration: 142, named_losses: [('ActivationMax Loss', 4856.269)], overall loss: 4856.26904296875\n",
      "Iteration: 143, named_losses: [('ActivationMax Loss', 3794.6675)], overall loss: 3794.66748046875\n",
      "Iteration: 144, named_losses: [('ActivationMax Loss', 2148.0815)], overall loss: 2148.08154296875\n",
      "Iteration: 145, named_losses: [('ActivationMax Loss', 9724.881)], overall loss: 9724.880859375\n",
      "Iteration: 146, named_losses: [('ActivationMax Loss', 9410.426)], overall loss: 9410.42578125\n",
      "Iteration: 147, named_losses: [('ActivationMax Loss', 2811.311)], overall loss: 2811.31103515625\n",
      "Iteration: 148, named_losses: [('ActivationMax Loss', 1103.0706)], overall loss: 1103.070556640625\n",
      "Iteration: 149, named_losses: [('ActivationMax Loss', 4264.126)], overall loss: 4264.1259765625\n",
      "Iteration: 150, named_losses: [('ActivationMax Loss', 1985.3561)], overall loss: 1985.3560791015625\n",
      "Iteration: 151, named_losses: [('ActivationMax Loss', 808.0925)], overall loss: 808.092529296875\n",
      "Iteration: 152, named_losses: [('ActivationMax Loss', 1004.887)], overall loss: 1004.8870239257812\n",
      "Iteration: 153, named_losses: [('ActivationMax Loss', 1917.3474)], overall loss: 1917.347412109375\n",
      "Iteration: 154, named_losses: [('ActivationMax Loss', 2401.93)], overall loss: 2401.929931640625\n",
      "Iteration: 155, named_losses: [('ActivationMax Loss', 1212.6282)], overall loss: 1212.628173828125\n",
      "Iteration: 156, named_losses: [('ActivationMax Loss', 3357.5342)], overall loss: 3357.5341796875\n",
      "Iteration: 157, named_losses: [('ActivationMax Loss', 1501.9489)], overall loss: 1501.9488525390625\n",
      "Iteration: 158, named_losses: [('ActivationMax Loss', 1896.1458)], overall loss: 1896.145751953125\n",
      "Iteration: 159, named_losses: [('ActivationMax Loss', 841.3587)], overall loss: 841.3587036132812\n",
      "Iteration: 160, named_losses: [('ActivationMax Loss', 1109.2728)], overall loss: 1109.2728271484375\n",
      "Iteration: 161, named_losses: [('ActivationMax Loss', 6404.1523)], overall loss: 6404.15234375\n",
      "Iteration: 162, named_losses: [('ActivationMax Loss', 3615.1228)], overall loss: 3615.122802734375\n",
      "Iteration: 163, named_losses: [('ActivationMax Loss', 7288.1426)], overall loss: 7288.142578125\n",
      "Iteration: 164, named_losses: [('ActivationMax Loss', 1027.826)], overall loss: 1027.8260498046875\n",
      "Iteration: 165, named_losses: [('ActivationMax Loss', 2302.82)], overall loss: 2302.820068359375\n",
      "Iteration: 166, named_losses: [('ActivationMax Loss', 2007.4407)], overall loss: 2007.440673828125\n",
      "Iteration: 167, named_losses: [('ActivationMax Loss', 3071.8962)], overall loss: 3071.896240234375\n",
      "Iteration: 168, named_losses: [('ActivationMax Loss', 6241.639)], overall loss: 6241.63916015625\n",
      "Iteration: 169, named_losses: [('ActivationMax Loss', 3473.154)], overall loss: 3473.154052734375\n",
      "Iteration: 170, named_losses: [('ActivationMax Loss', 15587.878)], overall loss: 15587.8779296875\n",
      "Iteration: 171, named_losses: [('ActivationMax Loss', 1661.0206)], overall loss: 1661.0206298828125\n",
      "Iteration: 172, named_losses: [('ActivationMax Loss', 1713.0669)], overall loss: 1713.06689453125\n",
      "Iteration: 173, named_losses: [('ActivationMax Loss', 12122.822)], overall loss: 12122.822265625\n",
      "Iteration: 174, named_losses: [('ActivationMax Loss', 4143.1763)], overall loss: 4143.17626953125\n",
      "Iteration: 175, named_losses: [('ActivationMax Loss', 2516.4756)], overall loss: 2516.4755859375\n",
      "Iteration: 176, named_losses: [('ActivationMax Loss', 2159.1658)], overall loss: 2159.165771484375\n",
      "Iteration: 177, named_losses: [('ActivationMax Loss', 358.60034)], overall loss: 358.600341796875\n",
      "Iteration: 178, named_losses: [('ActivationMax Loss', 3701.4373)], overall loss: 3701.437255859375\n",
      "Iteration: 179, named_losses: [('ActivationMax Loss', 4722.435)], overall loss: 4722.43505859375\n",
      "Iteration: 180, named_losses: [('ActivationMax Loss', 3951.368)], overall loss: 3951.367919921875\n",
      "Iteration: 181, named_losses: [('ActivationMax Loss', 1926.3826)], overall loss: 1926.382568359375\n",
      "Iteration: 182, named_losses: [('ActivationMax Loss', 5562.9316)], overall loss: 5562.931640625\n",
      "Iteration: 183, named_losses: [('ActivationMax Loss', 3154.992)], overall loss: 3154.991943359375\n",
      "Iteration: 184, named_losses: [('ActivationMax Loss', 4019.59)], overall loss: 4019.590087890625\n",
      "Iteration: 185, named_losses: [('ActivationMax Loss', 1283.835)], overall loss: 1283.8349609375\n",
      "Iteration: 186, named_losses: [('ActivationMax Loss', 1597.1127)], overall loss: 1597.1126708984375\n",
      "Iteration: 187, named_losses: [('ActivationMax Loss', 2334.8184)], overall loss: 2334.818359375\n",
      "Iteration: 188, named_losses: [('ActivationMax Loss', 1193.1599)], overall loss: 1193.159912109375\n",
      "Iteration: 189, named_losses: [('ActivationMax Loss', 4854.883)], overall loss: 4854.8828125\n",
      "Iteration: 190, named_losses: [('ActivationMax Loss', 2274.4985)], overall loss: 2274.49853515625\n",
      "Iteration: 191, named_losses: [('ActivationMax Loss', 1393.8829)], overall loss: 1393.8829345703125\n",
      "Iteration: 192, named_losses: [('ActivationMax Loss', 4649.2295)], overall loss: 4649.2294921875\n",
      "Iteration: 193, named_losses: [('ActivationMax Loss', 2437.6094)], overall loss: 2437.609375\n",
      "Iteration: 194, named_losses: [('ActivationMax Loss', 709.8696)], overall loss: 709.86962890625\n",
      "Iteration: 195, named_losses: [('ActivationMax Loss', 2369.2456)], overall loss: 2369.24560546875\n",
      "Iteration: 196, named_losses: [('ActivationMax Loss', 1341.5)], overall loss: 1341.5\n",
      "Iteration: 197, named_losses: [('ActivationMax Loss', 1275.5353)], overall loss: 1275.5352783203125\n",
      "Iteration: 198, named_losses: [('ActivationMax Loss', 1621.8068)], overall loss: 1621.8067626953125\n",
      "Iteration: 199, named_losses: [('ActivationMax Loss', 1711.5688)], overall loss: 1711.56884765625\n",
      "Iteration: 200, named_losses: [('ActivationMax Loss', 12128.116)], overall loss: 12128.1162109375\n",
      "Iteration: 201, named_losses: [('ActivationMax Loss', 3816.9954)], overall loss: 3816.995361328125\n",
      "Iteration: 202, named_losses: [('ActivationMax Loss', 4862.2773)], overall loss: 4862.27734375\n",
      "Iteration: 203, named_losses: [('ActivationMax Loss', 3588.694)], overall loss: 3588.694091796875\n",
      "Iteration: 204, named_losses: [('ActivationMax Loss', 928.52747)], overall loss: 928.5274658203125\n",
      "Iteration: 205, named_losses: [('ActivationMax Loss', 414.2241)], overall loss: 414.2240905761719\n",
      "Iteration: 206, named_losses: [('ActivationMax Loss', 3744.8604)], overall loss: 3744.8603515625\n",
      "Iteration: 207, named_losses: [('ActivationMax Loss', 3915.2776)], overall loss: 3915.277587890625\n",
      "Iteration: 208, named_losses: [('ActivationMax Loss', 1626.6201)], overall loss: 1626.6201171875\n",
      "Iteration: 209, named_losses: [('ActivationMax Loss', 5455.6694)], overall loss: 5455.66943359375\n",
      "Iteration: 210, named_losses: [('ActivationMax Loss', 4324.23)], overall loss: 4324.22998046875\n",
      "Iteration: 211, named_losses: [('ActivationMax Loss', 1374.067)], overall loss: 1374.0670166015625\n",
      "Iteration: 212, named_losses: [('ActivationMax Loss', 1799.4849)], overall loss: 1799.48486328125\n",
      "Iteration: 213, named_losses: [('ActivationMax Loss', 1594.4581)], overall loss: 1594.4581298828125\n",
      "Iteration: 214, named_losses: [('ActivationMax Loss', 7476.698)], overall loss: 7476.6982421875\n",
      "Iteration: 215, named_losses: [('ActivationMax Loss', 1091.9889)], overall loss: 1091.9888916015625\n",
      "Iteration: 216, named_losses: [('ActivationMax Loss', 4751.0835)], overall loss: 4751.08349609375\n",
      "Iteration: 217, named_losses: [('ActivationMax Loss', 1712.8612)], overall loss: 1712.8612060546875\n",
      "Iteration: 218, named_losses: [('ActivationMax Loss', 1991.8441)], overall loss: 1991.8441162109375\n",
      "Iteration: 219, named_losses: [('ActivationMax Loss', 6793.44)], overall loss: 6793.43994140625\n",
      "Iteration: 220, named_losses: [('ActivationMax Loss', 3791.3684)], overall loss: 3791.368408203125\n",
      "Iteration: 221, named_losses: [('ActivationMax Loss', 2407.728)], overall loss: 2407.72802734375\n",
      "Iteration: 222, named_losses: [('ActivationMax Loss', 3975.5215)], overall loss: 3975.521484375\n",
      "Iteration: 223, named_losses: [('ActivationMax Loss', 1935.0946)], overall loss: 1935.0946044921875\n",
      "Iteration: 224, named_losses: [('ActivationMax Loss', 1675.5919)], overall loss: 1675.5919189453125\n",
      "Iteration: 225, named_losses: [('ActivationMax Loss', 9418.739)], overall loss: 9418.7392578125\n",
      "Iteration: 226, named_losses: [('ActivationMax Loss', 2162.6316)], overall loss: 2162.631591796875\n",
      "Iteration: 227, named_losses: [('ActivationMax Loss', 962.7498)], overall loss: 962.7498168945312\n",
      "Iteration: 228, named_losses: [('ActivationMax Loss', 7940.7715)], overall loss: 7940.771484375\n",
      "Iteration: 229, named_losses: [('ActivationMax Loss', 4352.732)], overall loss: 4352.73193359375\n",
      "Iteration: 230, named_losses: [('ActivationMax Loss', 9377.334)], overall loss: 9377.333984375\n",
      "Iteration: 231, named_losses: [('ActivationMax Loss', 2876.29)], overall loss: 2876.2900390625\n",
      "Iteration: 232, named_losses: [('ActivationMax Loss', 1540.2704)], overall loss: 1540.2703857421875\n",
      "Iteration: 233, named_losses: [('ActivationMax Loss', 3371.9941)], overall loss: 3371.994140625\n",
      "Iteration: 234, named_losses: [('ActivationMax Loss', 1515.3345)], overall loss: 1515.33447265625\n",
      "Iteration: 235, named_losses: [('ActivationMax Loss', 1985.1259)], overall loss: 1985.1258544921875\n",
      "Iteration: 236, named_losses: [('ActivationMax Loss', 895.52905)], overall loss: 895.529052734375\n",
      "Iteration: 237, named_losses: [('ActivationMax Loss', 3240.2263)], overall loss: 3240.226318359375\n",
      "Iteration: 238, named_losses: [('ActivationMax Loss', 2522.1572)], overall loss: 2522.1572265625\n",
      "Iteration: 239, named_losses: [('ActivationMax Loss', 1862.1583)], overall loss: 1862.1583251953125\n",
      "Iteration: 240, named_losses: [('ActivationMax Loss', 2939.3784)], overall loss: 2939.37841796875\n",
      "Iteration: 241, named_losses: [('ActivationMax Loss', 4105.573)], overall loss: 4105.5732421875\n",
      "Iteration: 242, named_losses: [('ActivationMax Loss', 1176.7815)], overall loss: 1176.781494140625\n",
      "Iteration: 243, named_losses: [('ActivationMax Loss', 11030.031)], overall loss: 11030.03125\n",
      "Iteration: 244, named_losses: [('ActivationMax Loss', 4290.0566)], overall loss: 4290.056640625\n",
      "Iteration: 245, named_losses: [('ActivationMax Loss', 5174.4883)], overall loss: 5174.48828125\n",
      "Iteration: 246, named_losses: [('ActivationMax Loss', 1849.1052)], overall loss: 1849.105224609375\n",
      "Iteration: 247, named_losses: [('ActivationMax Loss', 2650.6453)], overall loss: 2650.645263671875\n",
      "Iteration: 248, named_losses: [('ActivationMax Loss', 1632.7236)], overall loss: 1632.7236328125\n",
      "Iteration: 249, named_losses: [('ActivationMax Loss', 4106.3203)], overall loss: 4106.3203125\n",
      "Iteration: 250, named_losses: [('ActivationMax Loss', 1551.3038)], overall loss: 1551.3038330078125\n",
      "Iteration: 251, named_losses: [('ActivationMax Loss', 3179.9985)], overall loss: 3179.99853515625\n",
      "Iteration: 252, named_losses: [('ActivationMax Loss', 5014.074)], overall loss: 5014.07421875\n",
      "Iteration: 253, named_losses: [('ActivationMax Loss', 1324.9523)], overall loss: 1324.9522705078125\n",
      "Iteration: 254, named_losses: [('ActivationMax Loss', 2710.109)], overall loss: 2710.10888671875\n",
      "Iteration: 255, named_losses: [('ActivationMax Loss', 2613.3352)], overall loss: 2613.335205078125\n",
      "Iteration: 256, named_losses: [('ActivationMax Loss', 2199.9023)], overall loss: 2199.90234375\n",
      "Iteration: 257, named_losses: [('ActivationMax Loss', 6749.446)], overall loss: 6749.44580078125\n",
      "Iteration: 258, named_losses: [('ActivationMax Loss', 1065.9095)], overall loss: 1065.9095458984375\n",
      "Iteration: 259, named_losses: [('ActivationMax Loss', 5060.1333)], overall loss: 5060.13330078125\n",
      "Iteration: 260, named_losses: [('ActivationMax Loss', 3559.5664)], overall loss: 3559.56640625\n",
      "Iteration: 261, named_losses: [('ActivationMax Loss', 1924.9323)], overall loss: 1924.9322509765625\n",
      "Iteration: 262, named_losses: [('ActivationMax Loss', 1034.8224)], overall loss: 1034.8223876953125\n",
      "Iteration: 263, named_losses: [('ActivationMax Loss', 2928.3079)], overall loss: 2928.307861328125\n",
      "Iteration: 264, named_losses: [('ActivationMax Loss', 11870.907)], overall loss: 11870.9072265625\n",
      "Iteration: 265, named_losses: [('ActivationMax Loss', 603.2757)], overall loss: 603.2756958007812\n",
      "Iteration: 266, named_losses: [('ActivationMax Loss', 4983.648)], overall loss: 4983.64794921875\n",
      "Iteration: 267, named_losses: [('ActivationMax Loss', 2495.6384)], overall loss: 2495.638427734375\n",
      "Iteration: 268, named_losses: [('ActivationMax Loss', 829.7577)], overall loss: 829.7576904296875\n",
      "Iteration: 269, named_losses: [('ActivationMax Loss', 2498.3057)], overall loss: 2498.3056640625\n",
      "Iteration: 270, named_losses: [('ActivationMax Loss', 2619.9043)], overall loss: 2619.904296875\n",
      "Iteration: 271, named_losses: [('ActivationMax Loss', 4148.3086)], overall loss: 4148.30859375\n",
      "Iteration: 272, named_losses: [('ActivationMax Loss', 1931.555)], overall loss: 1931.5550537109375\n",
      "Iteration: 273, named_losses: [('ActivationMax Loss', 2814.5876)], overall loss: 2814.587646484375\n",
      "Iteration: 274, named_losses: [('ActivationMax Loss', 1276.8263)], overall loss: 1276.8262939453125\n",
      "Iteration: 275, named_losses: [('ActivationMax Loss', 1744.5061)], overall loss: 1744.506103515625\n",
      "Iteration: 276, named_losses: [('ActivationMax Loss', 3721.2258)], overall loss: 3721.225830078125\n",
      "Iteration: 277, named_losses: [('ActivationMax Loss', 10703.948)], overall loss: 10703.9482421875\n",
      "Iteration: 278, named_losses: [('ActivationMax Loss', 9814.738)], overall loss: 9814.73828125\n",
      "Iteration: 279, named_losses: [('ActivationMax Loss', 2354.0703)], overall loss: 2354.0703125\n",
      "Iteration: 280, named_losses: [('ActivationMax Loss', 5887.9595)], overall loss: 5887.95947265625\n",
      "Iteration: 281, named_losses: [('ActivationMax Loss', 4359.2188)], overall loss: 4359.21875\n",
      "Iteration: 282, named_losses: [('ActivationMax Loss', 2060.1692)], overall loss: 2060.169189453125\n",
      "Iteration: 283, named_losses: [('ActivationMax Loss', 973.95197)], overall loss: 973.9519653320312\n",
      "Iteration: 284, named_losses: [('ActivationMax Loss', 2434.871)], overall loss: 2434.87109375\n",
      "Iteration: 285, named_losses: [('ActivationMax Loss', 1474.9497)], overall loss: 1474.94970703125\n",
      "Iteration: 286, named_losses: [('ActivationMax Loss', 3239.1008)], overall loss: 3239.100830078125\n",
      "Iteration: 287, named_losses: [('ActivationMax Loss', 6691.09)], overall loss: 6691.08984375\n",
      "Iteration: 288, named_losses: [('ActivationMax Loss', 2793.6853)], overall loss: 2793.685302734375\n",
      "Iteration: 289, named_losses: [('ActivationMax Loss', 1975.2291)], overall loss: 1975.2291259765625\n",
      "Iteration: 290, named_losses: [('ActivationMax Loss', 1175.8667)], overall loss: 1175.86669921875\n",
      "Iteration: 291, named_losses: [('ActivationMax Loss', 2149.7932)], overall loss: 2149.793212890625\n",
      "Iteration: 292, named_losses: [('ActivationMax Loss', 2288.4695)], overall loss: 2288.469482421875\n",
      "Iteration: 293, named_losses: [('ActivationMax Loss', 4015.0872)], overall loss: 4015.087158203125\n",
      "Iteration: 294, named_losses: [('ActivationMax Loss', 4548.746)], overall loss: 4548.74609375\n",
      "Iteration: 295, named_losses: [('ActivationMax Loss', 2099.35)], overall loss: 2099.35009765625\n",
      "Iteration: 296, named_losses: [('ActivationMax Loss', 1747.5612)], overall loss: 1747.5611572265625\n",
      "Iteration: 297, named_losses: [('ActivationMax Loss', 1403.996)], overall loss: 1403.9959716796875\n",
      "Iteration: 298, named_losses: [('ActivationMax Loss', 7368.6475)], overall loss: 7368.6474609375\n",
      "Iteration: 299, named_losses: [('ActivationMax Loss', 4069.389)], overall loss: 4069.388916015625\n",
      "Iteration: 300, named_losses: [('ActivationMax Loss', 1731.527)], overall loss: 1731.5269775390625\n",
      "Iteration: 301, named_losses: [('ActivationMax Loss', 3478.8777)], overall loss: 3478.877685546875\n",
      "Iteration: 302, named_losses: [('ActivationMax Loss', 1108.9607)], overall loss: 1108.960693359375\n",
      "Iteration: 303, named_losses: [('ActivationMax Loss', 4677.137)], overall loss: 4677.13720703125\n",
      "Iteration: 304, named_losses: [('ActivationMax Loss', 1367.4968)], overall loss: 1367.496826171875\n",
      "Iteration: 305, named_losses: [('ActivationMax Loss', 16180.98)], overall loss: 16180.98046875\n",
      "Iteration: 306, named_losses: [('ActivationMax Loss', 2175.481)], overall loss: 2175.48095703125\n",
      "Iteration: 307, named_losses: [('ActivationMax Loss', 2813.231)], overall loss: 2813.23095703125\n",
      "Iteration: 308, named_losses: [('ActivationMax Loss', 4282.921)], overall loss: 4282.9208984375\n",
      "Iteration: 309, named_losses: [('ActivationMax Loss', 2070.3848)], overall loss: 2070.384765625\n",
      "Iteration: 310, named_losses: [('ActivationMax Loss', 16958.395)], overall loss: 16958.39453125\n",
      "Iteration: 311, named_losses: [('ActivationMax Loss', 8909.671)], overall loss: 8909.6708984375\n",
      "Iteration: 312, named_losses: [('ActivationMax Loss', 3460.7795)], overall loss: 3460.779541015625\n",
      "Iteration: 313, named_losses: [('ActivationMax Loss', 1370.995)], overall loss: 1370.9949951171875\n",
      "Iteration: 314, named_losses: [('ActivationMax Loss', 1040.9218)], overall loss: 1040.9217529296875\n",
      "Iteration: 315, named_losses: [('ActivationMax Loss', 791.8905)], overall loss: 791.8905029296875\n",
      "Iteration: 316, named_losses: [('ActivationMax Loss', 683.24164)], overall loss: 683.2416381835938\n",
      "Iteration: 317, named_losses: [('ActivationMax Loss', 9767.562)], overall loss: 9767.5615234375\n",
      "Iteration: 318, named_losses: [('ActivationMax Loss', 4759.077)], overall loss: 4759.0771484375\n",
      "Iteration: 319, named_losses: [('ActivationMax Loss', 574.59436)], overall loss: 574.5943603515625\n",
      "Iteration: 320, named_losses: [('ActivationMax Loss', 447.12207)], overall loss: 447.1220703125\n",
      "Iteration: 321, named_losses: [('ActivationMax Loss', 4362.028)], overall loss: 4362.02783203125\n",
      "Iteration: 322, named_losses: [('ActivationMax Loss', 16635.117)], overall loss: 16635.1171875\n",
      "Iteration: 323, named_losses: [('ActivationMax Loss', 7269.1953)], overall loss: 7269.1953125\n",
      "Iteration: 324, named_losses: [('ActivationMax Loss', 17389.629)], overall loss: 17389.62890625\n",
      "Iteration: 325, named_losses: [('ActivationMax Loss', 4184.617)], overall loss: 4184.6171875\n",
      "Iteration: 326, named_losses: [('ActivationMax Loss', 445.69357)], overall loss: 445.6935729980469\n",
      "Iteration: 327, named_losses: [('ActivationMax Loss', 15009.848)], overall loss: 15009.84765625\n",
      "Iteration: 328, named_losses: [('ActivationMax Loss', 6661.1685)], overall loss: 6661.16845703125\n",
      "Iteration: 329, named_losses: [('ActivationMax Loss', 1064.9486)], overall loss: 1064.9486083984375\n",
      "Iteration: 330, named_losses: [('ActivationMax Loss', 2730.9158)], overall loss: 2730.915771484375\n",
      "Iteration: 331, named_losses: [('ActivationMax Loss', 2884.3184)], overall loss: 2884.318359375\n",
      "Iteration: 332, named_losses: [('ActivationMax Loss', 792.2437)], overall loss: 792.2437133789062\n",
      "Iteration: 333, named_losses: [('ActivationMax Loss', 4624.839)], overall loss: 4624.8388671875\n",
      "Iteration: 334, named_losses: [('ActivationMax Loss', 1381.7534)], overall loss: 1381.75341796875\n",
      "Iteration: 335, named_losses: [('ActivationMax Loss', 2580.0378)], overall loss: 2580.037841796875\n",
      "Iteration: 336, named_losses: [('ActivationMax Loss', 11636.673)], overall loss: 11636.6728515625\n",
      "Iteration: 337, named_losses: [('ActivationMax Loss', 1817.383)], overall loss: 1817.383056640625\n",
      "Iteration: 338, named_losses: [('ActivationMax Loss', 918.6678)], overall loss: 918.6677856445312\n",
      "Iteration: 339, named_losses: [('ActivationMax Loss', 2020.5393)], overall loss: 2020.539306640625\n",
      "Iteration: 340, named_losses: [('ActivationMax Loss', 960.7161)], overall loss: 960.7161254882812\n",
      "Iteration: 341, named_losses: [('ActivationMax Loss', 645.8652)], overall loss: 645.8651733398438\n",
      "Iteration: 342, named_losses: [('ActivationMax Loss', 6030.899)], overall loss: 6030.89892578125\n",
      "Iteration: 343, named_losses: [('ActivationMax Loss', 619.0232)], overall loss: 619.023193359375\n",
      "Iteration: 344, named_losses: [('ActivationMax Loss', 2104.22)], overall loss: 2104.219970703125\n",
      "Iteration: 345, named_losses: [('ActivationMax Loss', 12827.228)], overall loss: 12827.2275390625\n",
      "Iteration: 346, named_losses: [('ActivationMax Loss', 3327.381)], overall loss: 3327.381103515625\n",
      "Iteration: 347, named_losses: [('ActivationMax Loss', 2304.8853)], overall loss: 2304.88525390625\n",
      "Iteration: 348, named_losses: [('ActivationMax Loss', 1698.7344)], overall loss: 1698.734375\n",
      "Iteration: 349, named_losses: [('ActivationMax Loss', 6301.874)], overall loss: 6301.8740234375\n",
      "Iteration: 350, named_losses: [('ActivationMax Loss', 3867.116)], overall loss: 3867.115966796875\n",
      "Iteration: 351, named_losses: [('ActivationMax Loss', 2633.6677)], overall loss: 2633.667724609375\n",
      "Iteration: 352, named_losses: [('ActivationMax Loss', 7578.445)], overall loss: 7578.44482421875\n",
      "Iteration: 353, named_losses: [('ActivationMax Loss', 688.82227)], overall loss: 688.822265625\n",
      "Iteration: 354, named_losses: [('ActivationMax Loss', 4908.8545)], overall loss: 4908.8544921875\n",
      "Iteration: 355, named_losses: [('ActivationMax Loss', 2149.3994)], overall loss: 2149.3994140625\n",
      "Iteration: 356, named_losses: [('ActivationMax Loss', 7041.822)], overall loss: 7041.82177734375\n",
      "Iteration: 357, named_losses: [('ActivationMax Loss', 2800.7585)], overall loss: 2800.758544921875\n",
      "Iteration: 358, named_losses: [('ActivationMax Loss', 970.52594)], overall loss: 970.5259399414062\n",
      "Iteration: 359, named_losses: [('ActivationMax Loss', 31018.86)], overall loss: 31018.859375\n",
      "Iteration: 360, named_losses: [('ActivationMax Loss', 10044.136)], overall loss: 10044.1357421875\n",
      "Iteration: 361, named_losses: [('ActivationMax Loss', 688.5587)], overall loss: 688.5587158203125\n",
      "Iteration: 362, named_losses: [('ActivationMax Loss', 2536.9443)], overall loss: 2536.9443359375\n",
      "Iteration: 363, named_losses: [('ActivationMax Loss', 4549.3643)], overall loss: 4549.3642578125\n",
      "Iteration: 364, named_losses: [('ActivationMax Loss', 308.613)], overall loss: 308.6130065917969\n",
      "Iteration: 365, named_losses: [('ActivationMax Loss', 3587.7407)], overall loss: 3587.74072265625\n",
      "Iteration: 366, named_losses: [('ActivationMax Loss', 3104.5474)], overall loss: 3104.54736328125\n",
      "Iteration: 367, named_losses: [('ActivationMax Loss', 628.51483)], overall loss: 628.5148315429688\n",
      "Iteration: 368, named_losses: [('ActivationMax Loss', 2331.008)], overall loss: 2331.008056640625\n",
      "Iteration: 369, named_losses: [('ActivationMax Loss', 4163.0347)], overall loss: 4163.03466796875\n",
      "Iteration: 370, named_losses: [('ActivationMax Loss', 1065.3589)], overall loss: 1065.35888671875\n",
      "Iteration: 371, named_losses: [('ActivationMax Loss', 2499.217)], overall loss: 2499.217041015625\n",
      "Iteration: 372, named_losses: [('ActivationMax Loss', 5317.755)], overall loss: 5317.7548828125\n",
      "Iteration: 373, named_losses: [('ActivationMax Loss', 1399.0162)], overall loss: 1399.0162353515625\n",
      "Iteration: 374, named_losses: [('ActivationMax Loss', 1976.7783)], overall loss: 1976.7783203125\n",
      "Iteration: 375, named_losses: [('ActivationMax Loss', 21284.053)], overall loss: 21284.052734375\n",
      "Iteration: 376, named_losses: [('ActivationMax Loss', 3333.7231)], overall loss: 3333.72314453125\n",
      "Iteration: 377, named_losses: [('ActivationMax Loss', 1823.6752)], overall loss: 1823.6751708984375\n",
      "Iteration: 378, named_losses: [('ActivationMax Loss', 4991.321)], overall loss: 4991.32080078125\n",
      "Iteration: 379, named_losses: [('ActivationMax Loss', 3599.7896)], overall loss: 3599.78955078125\n",
      "Iteration: 380, named_losses: [('ActivationMax Loss', 1602.3242)], overall loss: 1602.32421875\n",
      "Iteration: 381, named_losses: [('ActivationMax Loss', 3899.3687)], overall loss: 3899.36865234375\n",
      "Iteration: 382, named_losses: [('ActivationMax Loss', 9224.297)], overall loss: 9224.296875\n",
      "Iteration: 383, named_losses: [('ActivationMax Loss', 3515.0342)], overall loss: 3515.0341796875\n",
      "Iteration: 384, named_losses: [('ActivationMax Loss', 4484.7974)], overall loss: 4484.79736328125\n",
      "Iteration: 385, named_losses: [('ActivationMax Loss', 5278.6523)], overall loss: 5278.65234375\n",
      "Iteration: 386, named_losses: [('ActivationMax Loss', 15379.147)], overall loss: 15379.1474609375\n",
      "Iteration: 387, named_losses: [('ActivationMax Loss', 7372.4897)], overall loss: 7372.48974609375\n",
      "Iteration: 388, named_losses: [('ActivationMax Loss', 1877.3153)], overall loss: 1877.3153076171875\n",
      "Iteration: 389, named_losses: [('ActivationMax Loss', 6549.3105)], overall loss: 6549.310546875\n",
      "Iteration: 390, named_losses: [('ActivationMax Loss', 1025.47)], overall loss: 1025.469970703125\n",
      "Iteration: 391, named_losses: [('ActivationMax Loss', 5829.973)], overall loss: 5829.97314453125\n",
      "Iteration: 392, named_losses: [('ActivationMax Loss', 2685.1477)], overall loss: 2685.147705078125\n",
      "Iteration: 393, named_losses: [('ActivationMax Loss', 1619.9417)], overall loss: 1619.941650390625\n",
      "Iteration: 394, named_losses: [('ActivationMax Loss', 5326.045)], overall loss: 5326.044921875\n",
      "Iteration: 395, named_losses: [('ActivationMax Loss', 3582.9583)], overall loss: 3582.958251953125\n",
      "Iteration: 396, named_losses: [('ActivationMax Loss', 1994.4523)], overall loss: 1994.4522705078125\n",
      "Iteration: 397, named_losses: [('ActivationMax Loss', 3319.2295)], overall loss: 3319.2294921875\n",
      "Iteration: 398, named_losses: [('ActivationMax Loss', 1362.4233)], overall loss: 1362.42333984375\n",
      "Iteration: 399, named_losses: [('ActivationMax Loss', 1066.8939)], overall loss: 1066.8939208984375\n",
      "Iteration: 400, named_losses: [('ActivationMax Loss', 5270.4805)], overall loss: 5270.48046875\n",
      "Iteration: 401, named_losses: [('ActivationMax Loss', 2253.997)], overall loss: 2253.9970703125\n",
      "Iteration: 402, named_losses: [('ActivationMax Loss', 2302.209)], overall loss: 2302.208984375\n",
      "Iteration: 403, named_losses: [('ActivationMax Loss', 5095.0693)], overall loss: 5095.0693359375\n",
      "Iteration: 404, named_losses: [('ActivationMax Loss', 5168.1235)], overall loss: 5168.12353515625\n",
      "Iteration: 405, named_losses: [('ActivationMax Loss', 634.2319)], overall loss: 634.2318725585938\n",
      "Iteration: 406, named_losses: [('ActivationMax Loss', 1659.3362)], overall loss: 1659.336181640625\n",
      "Iteration: 407, named_losses: [('ActivationMax Loss', 3085.7192)], overall loss: 3085.71923828125\n",
      "Iteration: 408, named_losses: [('ActivationMax Loss', 5231.8247)], overall loss: 5231.82470703125\n",
      "Iteration: 409, named_losses: [('ActivationMax Loss', 3582.4211)], overall loss: 3582.421142578125\n",
      "Iteration: 410, named_losses: [('ActivationMax Loss', 5162.956)], overall loss: 5162.9560546875\n",
      "Iteration: 411, named_losses: [('ActivationMax Loss', 4448.825)], overall loss: 4448.8251953125\n",
      "Iteration: 412, named_losses: [('ActivationMax Loss', 4423.332)], overall loss: 4423.33203125\n",
      "Iteration: 413, named_losses: [('ActivationMax Loss', 1868.6256)], overall loss: 1868.6256103515625\n",
      "Iteration: 414, named_losses: [('ActivationMax Loss', 12771.38)], overall loss: 12771.3798828125\n",
      "Iteration: 415, named_losses: [('ActivationMax Loss', 1195.2109)], overall loss: 1195.2109375\n",
      "Iteration: 416, named_losses: [('ActivationMax Loss', 3021.2913)], overall loss: 3021.291259765625\n",
      "Iteration: 417, named_losses: [('ActivationMax Loss', 8759.211)], overall loss: 8759.2109375\n",
      "Iteration: 418, named_losses: [('ActivationMax Loss', 631.2306)], overall loss: 631.2305908203125\n",
      "Iteration: 419, named_losses: [('ActivationMax Loss', 1578.6257)], overall loss: 1578.625732421875\n",
      "Iteration: 420, named_losses: [('ActivationMax Loss', 9931.453)], overall loss: 9931.453125\n",
      "Iteration: 421, named_losses: [('ActivationMax Loss', 6636.963)], overall loss: 6636.962890625\n",
      "Iteration: 422, named_losses: [('ActivationMax Loss', 13072.334)], overall loss: 13072.333984375\n",
      "Iteration: 423, named_losses: [('ActivationMax Loss', 2715.8052)], overall loss: 2715.80517578125\n",
      "Iteration: 424, named_losses: [('ActivationMax Loss', 8819.8)], overall loss: 8819.7998046875\n",
      "Iteration: 425, named_losses: [('ActivationMax Loss', 6690.098)], overall loss: 6690.09814453125\n",
      "Iteration: 426, named_losses: [('ActivationMax Loss', 8524.547)], overall loss: 8524.546875\n",
      "Iteration: 427, named_losses: [('ActivationMax Loss', 2390.1428)], overall loss: 2390.142822265625\n",
      "Iteration: 428, named_losses: [('ActivationMax Loss', 3079.675)], overall loss: 3079.675048828125\n",
      "Iteration: 429, named_losses: [('ActivationMax Loss', 3306.0417)], overall loss: 3306.041748046875\n",
      "Iteration: 430, named_losses: [('ActivationMax Loss', 1352.7994)], overall loss: 1352.7994384765625\n",
      "Iteration: 431, named_losses: [('ActivationMax Loss', 5853.826)], overall loss: 5853.826171875\n",
      "Iteration: 432, named_losses: [('ActivationMax Loss', 835.0217)], overall loss: 835.021728515625\n",
      "Iteration: 433, named_losses: [('ActivationMax Loss', 2130.4023)], overall loss: 2130.40234375\n",
      "Iteration: 434, named_losses: [('ActivationMax Loss', 244.48358)], overall loss: 244.48358154296875\n",
      "Iteration: 435, named_losses: [('ActivationMax Loss', 2111.4993)], overall loss: 2111.499267578125\n",
      "Iteration: 436, named_losses: [('ActivationMax Loss', 5484.6895)], overall loss: 5484.689453125\n",
      "Iteration: 437, named_losses: [('ActivationMax Loss', 1535.6444)], overall loss: 1535.6444091796875\n",
      "Iteration: 438, named_losses: [('ActivationMax Loss', 5966.458)], overall loss: 5966.4580078125\n",
      "Iteration: 439, named_losses: [('ActivationMax Loss', 1273.8428)], overall loss: 1273.8427734375\n",
      "Iteration: 440, named_losses: [('ActivationMax Loss', 9510.508)], overall loss: 9510.5078125\n",
      "Iteration: 441, named_losses: [('ActivationMax Loss', 1470.003)], overall loss: 1470.0030517578125\n",
      "Iteration: 442, named_losses: [('ActivationMax Loss', 1864.383)], overall loss: 1864.383056640625\n",
      "Iteration: 443, named_losses: [('ActivationMax Loss', 5433.634)], overall loss: 5433.6337890625\n",
      "Iteration: 444, named_losses: [('ActivationMax Loss', 828.3985)], overall loss: 828.3984985351562\n",
      "Iteration: 445, named_losses: [('ActivationMax Loss', 2589.1958)], overall loss: 2589.19580078125\n",
      "Iteration: 446, named_losses: [('ActivationMax Loss', 2662.7822)], overall loss: 2662.7822265625\n",
      "Iteration: 447, named_losses: [('ActivationMax Loss', 2438.7683)], overall loss: 2438.768310546875\n",
      "Iteration: 448, named_losses: [('ActivationMax Loss', 1607.2017)], overall loss: 1607.20166015625\n",
      "Iteration: 449, named_losses: [('ActivationMax Loss', 9160.064)], overall loss: 9160.064453125\n",
      "Iteration: 450, named_losses: [('ActivationMax Loss', 1564.1841)], overall loss: 1564.18408203125\n",
      "Iteration: 451, named_losses: [('ActivationMax Loss', 655.1315)], overall loss: 655.1314697265625\n",
      "Iteration: 452, named_losses: [('ActivationMax Loss', 4880.57)], overall loss: 4880.56982421875\n",
      "Iteration: 453, named_losses: [('ActivationMax Loss', 2815.7422)], overall loss: 2815.7421875\n",
      "Iteration: 454, named_losses: [('ActivationMax Loss', 12528.232)], overall loss: 12528.232421875\n",
      "Iteration: 455, named_losses: [('ActivationMax Loss', 1594.2169)], overall loss: 1594.2169189453125\n",
      "Iteration: 456, named_losses: [('ActivationMax Loss', 2678.4387)], overall loss: 2678.438720703125\n",
      "Iteration: 457, named_losses: [('ActivationMax Loss', 4963.011)], overall loss: 4963.01123046875\n",
      "Iteration: 458, named_losses: [('ActivationMax Loss', 3182.0493)], overall loss: 3182.04931640625\n",
      "Iteration: 459, named_losses: [('ActivationMax Loss', 7153.005)], overall loss: 7153.0048828125\n",
      "Iteration: 460, named_losses: [('ActivationMax Loss', 4182.9033)], overall loss: 4182.9033203125\n",
      "Iteration: 461, named_losses: [('ActivationMax Loss', 859.37006)], overall loss: 859.3700561523438\n",
      "Iteration: 462, named_losses: [('ActivationMax Loss', 10847.802)], overall loss: 10847.8017578125\n",
      "Iteration: 463, named_losses: [('ActivationMax Loss', 432.27316)], overall loss: 432.2731628417969\n",
      "Iteration: 464, named_losses: [('ActivationMax Loss', 5080.1357)], overall loss: 5080.1357421875\n",
      "Iteration: 465, named_losses: [('ActivationMax Loss', 2683.905)], overall loss: 2683.905029296875\n",
      "Iteration: 466, named_losses: [('ActivationMax Loss', 3002.2344)], overall loss: 3002.234375\n",
      "Iteration: 467, named_losses: [('ActivationMax Loss', 3094.3804)], overall loss: 3094.38037109375\n",
      "Iteration: 468, named_losses: [('ActivationMax Loss', 2035.5009)], overall loss: 2035.5008544921875\n",
      "Iteration: 469, named_losses: [('ActivationMax Loss', 1634.6583)], overall loss: 1634.6583251953125\n",
      "Iteration: 470, named_losses: [('ActivationMax Loss', 1469.4424)], overall loss: 1469.4423828125\n",
      "Iteration: 471, named_losses: [('ActivationMax Loss', 5504.7476)], overall loss: 5504.74755859375\n",
      "Iteration: 472, named_losses: [('ActivationMax Loss', 1265.8302)], overall loss: 1265.8302001953125\n",
      "Iteration: 473, named_losses: [('ActivationMax Loss', 3518.434)], overall loss: 3518.43408203125\n",
      "Iteration: 474, named_losses: [('ActivationMax Loss', 5794.0947)], overall loss: 5794.0947265625\n",
      "Iteration: 475, named_losses: [('ActivationMax Loss', 1996.898)], overall loss: 1996.89794921875\n",
      "Iteration: 476, named_losses: [('ActivationMax Loss', 1159.9141)], overall loss: 1159.9140625\n",
      "Iteration: 477, named_losses: [('ActivationMax Loss', 7299.8716)], overall loss: 7299.87158203125\n",
      "Iteration: 478, named_losses: [('ActivationMax Loss', 17535.588)], overall loss: 17535.587890625\n",
      "Iteration: 479, named_losses: [('ActivationMax Loss', 1478.5186)], overall loss: 1478.5185546875\n",
      "Iteration: 480, named_losses: [('ActivationMax Loss', 6476.172)], overall loss: 6476.171875\n",
      "Iteration: 481, named_losses: [('ActivationMax Loss', 3049.8242)], overall loss: 3049.82421875\n",
      "Iteration: 482, named_losses: [('ActivationMax Loss', 610.50433)], overall loss: 610.5043334960938\n",
      "Iteration: 483, named_losses: [('ActivationMax Loss', 3959.059)], overall loss: 3959.05908203125\n",
      "Iteration: 484, named_losses: [('ActivationMax Loss', 4946.7896)], overall loss: 4946.78955078125\n",
      "Iteration: 485, named_losses: [('ActivationMax Loss', 2898.1694)], overall loss: 2898.16943359375\n",
      "Iteration: 486, named_losses: [('ActivationMax Loss', 3656.073)], overall loss: 3656.072998046875\n",
      "Iteration: 487, named_losses: [('ActivationMax Loss', 1402.0864)], overall loss: 1402.08642578125\n",
      "Iteration: 488, named_losses: [('ActivationMax Loss', 3207.2192)], overall loss: 3207.21923828125\n",
      "Iteration: 489, named_losses: [('ActivationMax Loss', 1023.29974)], overall loss: 1023.2997436523438\n",
      "Iteration: 490, named_losses: [('ActivationMax Loss', 1298.953)], overall loss: 1298.9530029296875\n",
      "Iteration: 491, named_losses: [('ActivationMax Loss', 2755.6858)], overall loss: 2755.685791015625\n",
      "Iteration: 492, named_losses: [('ActivationMax Loss', 510.2183)], overall loss: 510.2182922363281\n",
      "Iteration: 493, named_losses: [('ActivationMax Loss', 5258.433)], overall loss: 5258.43310546875\n",
      "Iteration: 494, named_losses: [('ActivationMax Loss', 3339.7488)], overall loss: 3339.748779296875\n",
      "Iteration: 495, named_losses: [('ActivationMax Loss', 3014.174)], overall loss: 3014.174072265625\n",
      "Iteration: 496, named_losses: [('ActivationMax Loss', 1584.4479)], overall loss: 1584.4478759765625\n",
      "Iteration: 497, named_losses: [('ActivationMax Loss', 4192.07)], overall loss: 4192.06982421875\n",
      "Iteration: 498, named_losses: [('ActivationMax Loss', 2725.5293)], overall loss: 2725.529296875\n",
      "Iteration: 499, named_losses: [('ActivationMax Loss', 464.94247)], overall loss: 464.9424743652344\n",
      "Iteration: 500, named_losses: [('ActivationMax Loss', 5252.601)], overall loss: 5252.60107421875\n"
     ],
     "output_type": "stream"
    },
    {
     "data": {
      "text/plain": "(-0.5, 27.5, 27.5, -0.5)"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 215
    },
    {
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from vis.utils import utils\n",
    "from vis.visualization import visualize_activation_with_losses\n",
    "from matplotlib import pyplot as plt\n",
    "model.encoder.summary()\n",
    "img = my_visualize_activation(model.encoder, desired_mean=0., layer_idx=35, max_iter=500, verbose=True,\n",
    "                                  lp_norm_weight=0, tv_weight=0, input_range=[0.,1.], input_modifiers=[Jitter(10)])\n",
    "\n",
    "plt.imshow(img.squeeze(), cmap='gray')\n",
    "plt.axis('off')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
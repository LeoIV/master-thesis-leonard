\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{parskip}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{acronym}
\usepackage[natbib=true]{biblatex}
\usepackage{amsmath}
\usepackage{dirtytalk}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{amsfonts}
\usepackage{csquotes}
\usepackage{pgffor}
% bold math symbols
\usepackage{bm}
\addbibresource{literature.bib}
\renewcommand{\baselinestretch}{1.5}
\newcounter{savepage}

\DeclarePairedDelimiterX{\infdivx}[2]{(}{)}{%
    #1\;\delimsize\|\;#2%
}
\newcommand{\kldiv}{D_{KL}\infdivx}
\DeclarePairedDelimiter{\norm}{\lVert}{\rVert}

\begin{document}

    \begin{titlepage}
        \centering
        \includegraphics[width=0.25\textwidth]{rublogo.png}\par
        {\scshape\huge\bfseries Semantic Representations in Variational Autoencoders as a Model of the Visual System \par}
        {\scshape\large Schriftliche Pr체fungsarbeit f체r die Master-Pr체fung des Studiengangs Angewandte Informatik an der Ruhr-Universit채t Bochum\par}
        \vspace{1em}
        vorgelegt von\par
        \vspace{2em}
        Leonard Papenmeier\par 108017257755\par
        \vspace{2em}
        01.01.1980\par

        \vfill
        Prof. Dr. Laurenz Wiskott\par
        M.Sc. Zahra Fayyaz


    \end{titlepage}
    \pagenumbering{Roman}
    \tableofcontents
    \newpage
    \setcounter{savepage}{\arabic{page}}
    \pagenumbering{arabic}


    \section{Introduction}\label{sec:introduction}


    \section{Theoretical Background}\label{sec:theoretical-background}
    \include{background}


    \section{Methods}\label{sec:methods}
    \input{methods}


    \section{Results}\label{sec:results}

    \subsection{Visual Features in Variational Autoencoders}\label{subsec:results_visual_features_in_variational_autoencoders}
    The following sections describe the results of the experiments on visual features in variational autoencoders.

    \begin{itemize}
        \item Results non-AlexNet-like-VAE on CelebA: especially layer 1 kernels
        \item Results AlexNet-like-VAE on ImageNet: especially layer 1 kernels
        \item Results AlexNet-like image classification CNN on ImageNet: especially layer 1 kernels
        \item Results AlexNet-like-VAE with frozen decoder from classification network
    \end{itemize}

    \subsubsection{AlexNet Image Classification}
    To make sure that the network structure of the \ac{VAE} is apt to generate Gabor wavelets, image classification was performed on ImageNet (see Figure~\ref{fig:alexnet} and Section~\ref{subsec:visual-features-variational-autoencoders} for the used network, see Section~\ref{ssec:imagenet} for ImageNet).
    As the accuracy was not of primary concern, the training was stopped during the tenth epoch (\textbf{If time: train all 100 epochs}), the top-1 training accuracy at this time was at 0.85.

    \begin{figure}
        \centering
        \includegraphics[width=0.9\textwidth]{images/alexnet_classification_l1_kernels.png}
        \caption[Image classification - Layer 1 Kernels]{Convolutional Kernels in the first layer of the image classification network. The filters are shown in their original size (11x11).}
        \label{fig:classification_layer1_kernels}
    \end{figure}

    Figure~\ref{fig:classification_layer1_kernels} shows all 256 convolutional kernels of the image classification network.
    It is easy to see that in many kernels, Gabor wavelet-like filters emerge.

    \subsection{Activity Correlation in \acp{VAE}}\label{subsec:results_activity-correlation-in-vaes}

    \subsection{Feature Map Stripes}\label{subsec:feature-map-stripes}

    \begin{figure}
        \centering
        \begin{subfigure}{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/stripes/original.jpg}
            \caption{The original image.}
            \label{subfig:stripes_original}
        \end{subfigure}
        \hfill
        \begin{subfigure}{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/stripes/leaky_re_lu_5.png}
            \caption{The feature maps after LeakyReLU 5}
            \label{subfig:lakyrelu5}
        \end{subfigure}
        \hfill
        \begin{subfigure}{0.3\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/stripes/max_pooling2d_3.png}
            \caption{The feature maps after max pooling of LeakyReLU 5}
            \label{subfig:maxpool}
        \end{subfigure}
        \caption{The original image and the feature maps after passing the image through the network until after the specified layer. The stripe artifacts can be observed in many feature maps in Subfigure~\ref{subfig:lakyrelu5}. They vanish after max-pooling (Subfigure~\ref{subfig:maxpool}).}
        \label{fig:stripes}
    \end{figure}


    One observation being made during the analysis of the networks was the emergence of striped artifacts in the networks feature maps (Figure~\ref{fig:stripes}).
    These stripes were observed in the Vanilla VAE, AlexNetVAE, as well as the AlexNet Classifier and might be also present in other networks (\textbf{CHECK THIS}).
    Apparently, the stripes are either always horizontal or vertical for one network type.
    If they are vertical, they can appear on the left or the right side of the same network.
    If they are horizontal, they appear either on the top or on the bottom of the same network.
    The exact reason why the networks show this behavior was not found, however some insights were won.

    \paragraph{Padding}
    The stripes occur due to the zero-padding in the network and the resulting contrast observed by the convolutional filters.
    Take Figure~\ref{fig:stripes}.
    Here, the stripes appear strongest on the bottom left of the image.
    Noteworthy, the stripes indicate less active regions in the feature map: The feature map has an activity of around zero everywhere except for the location of the stripes.
    Here, the activity is strongly negative.

    A comparison with the original image (Figure~\ref{subfig:stripes_original}) shows that for the left side of the image, the contrast is highest on the bottom if the image is zero-padded\footnote{Zero-padding can be understood as adding black pixels around the image.}.
    Importantly, the contrast is as high on the bottom of the image, the right side, and the right side of the top of the image.
    However, for this network, the stripes seem to occur for a sharp shift of black on the left to white on the right.

    \begin{figure}
        \centering
        \foreach \n in {0,...,11}{
            \begin{subfigure}{0.05\textwidth}
                \frame{\includegraphics[width=\textwidth]{images/stripes/test_images/original\n.jpg}}
                \caption{}
                \label{subfig:test_images_stripes\n}
            \end{subfigure}
            \hfill
        }
        \caption{The test images used to analyze the networks behavior.}
        \label{fig:test_images_stripes}
    \end{figure}

    To better understand the behavior, the network was applied to a set of artifical test images (Figure~\ref{fig:test_images_stripes}).
    All different feature maps with respect to each image can be found in the appendix.

    \begin{figure}
        \centering
        \begin{subfigure}{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/stripes/test_img_9/leaky_re_lu_5.png}
            \caption{The original image.}
            \label{subfig:stipes_test_img_leakyrelu5}
        \end{subfigure}
        \hfill
        \begin{subfigure}{0.45\textwidth}
            \centering
            \includegraphics[width=\textwidth]{images/stripes/test_img_9/max_pooling2d_3.png}
            \caption{The feature maps after LeakyReLU 5}
            \label{subfig:stripes_test_img_maxpool3}
        \end{subfigure}
        \caption{The feature maps with respect to test image~\ref{subfig:test_images_stripes8}.}
        \label{fig:stripes_test_img}
    \end{figure}

    Subfigure~\ref{subfig:test_images_stripes8} and~\ref{subfig:test_images_stripes11} turned to be most equally high insightful.
    Figure~\ref{fig:stripes_test_img} shows the feature map after the last LeakyReLU (LeakyReLU 5) activation of the network given this input image (Subfigure~\ref{subfig:stipes_test_img_leakyrelu5}) as well as the feature map after max-pooling of this feature map (Subfigure~\ref{subfig:stripes_test_img_maxpool3}).
    Multiple things can be observed in Subfigure~\ref{subfig:stipes_test_img_leakyrelu5}.
    Firstly, the feature map in the first column of the fifth row resembles the input stimulus itself.
    The fact that this feature map shows most of the activity (especially after max-pooling, see Subfigure~\ref{subfig:stripes_test_img_maxpool3}) has been observed for natural images as well, however not the resemblance of the input stimulus.
    Except for this feature map, stripes emerge either on the bottom of the left side or the bottom of the right side of the feature map.
    For the bottom of the left side, this is where the sharp black-white contrast is.
    The bottom of the right side is more complicated.
    Here the test image was black and the \say{contrast} is a black-black contrast - or no contrast at all.
    However, this is only true for the first feature map\footnote{The first feature maps are not shown here.}.
    The following feature maps, again, are zero-padded.
    However, due to the bias term in the convolutions, these might be non-zero in the bottom-right and top-left square of the image, thus leading to a contrast.
    This explains why the network can be sensitive towards these black-black contrasts in the input image.


    \section{Discussion}\label{sec:discussion}

    \subsection{Visual Features in Variational Autoencoders}\label{subsec:discussion_visual_features_in_variational_autoencoders}
    \begin{itemize}
        \item Reconstructions of AlexNet-VAE don't look natural at all, this might be because ImageNet, unlike CelebA, is not properly aligned and contains images from a large variety of classes.
        This might be another hint towards the assumption that \acp{VAE} are no suitable model for semantic representations
        \item How does it come that supervised models seem to be a good representation of \ac{IT} cortical representation~\citep{khaligh2014deep}? Maybe the brain learns in a \say{supervised} manner in the sense that if you have never seen a horse, you need someone to tell you that that is a horse in order to make sense out of it.
        However, you might, at least, be able to recognize that it is an animal.
        Also, if someone tells you \say{This is a horse.}, you'll be able to recognize horses from different orientations and in different body positions without further training.
        This is quite different from how \acp{CNN} capture animals and is a strong hint to that supervised \acp{CNN} alone a no sufficient model for cortical IT representations.
    \end{itemize}


    \section{Conclusion}\label{sec:conclusion}

    \newpage
    \printbibliography

    \newpage
    \pagenumbering{Roman}
    \setcounter{page}{\thesavepage}
    \section*{Acronyms}
    \begin{acronym}[TDMA]
        \acro{VAE}{Variational Autoencoder}
        \acrodefplural{VAE}{Variational Autoencoders}
        \acro{CNN}{Convolutional Neural Network}
        \acrodefplural{CNN}{Convolutional Neural Networks}
        \acro{IT}{Inferior Temporal Cortex}
        \acro{ReLU}{Rectified Linear Unit}
        \acro{LeakyReLU}{Leaky Rectified Linear Unit}
        \acro{ILSVRC2017}{Large Scale Visual Recognition Challenge 2017}
        \acro{MSE}{Mean Squared Error}
        \acro{KL-divergence}{Kullback-Leibler divergence}
        \acro{ELBO}{Evidence Lower Bound}
        \acro{PDF}{Probability Density Function}
        \acro{MSE}{Mean Squared Error}
        \acro{GAN}{Generative Adversarial Network}
    \end{acronym}
    \newpage
    \listoffigures
    \newpage
    \listoftables
    \newpage
    \include{erklaerung}


\end{document}

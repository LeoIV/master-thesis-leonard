\documentclass[11pt]{article}
\usepackage[utf8]{inputenc}
\usepackage{graphicx}
\usepackage{geometry}
\usepackage{parskip}
\usepackage{subcaption}
\usepackage{wrapfig}
\usepackage{acronym}
\usepackage[natbib=true]{biblatex}
\usepackage{amsmath}
\usepackage{dirtytalk}
\usepackage{hyperref}
\usepackage{amsfonts}
\addbibresource{literature.bib}
\renewcommand{\baselinestretch}{1.5}
\newcounter{savepage}

\begin{document}

    \begin{titlepage}
        \centering
        \includegraphics[width=0.25\textwidth]{rublogo.png}\par
        {\scshape\huge\bfseries Semantic Representations in Variational Autoencoders as a Model of the Visual System \par}
        {\scshape\large Schriftliche Pr체fungsarbeit f체r die Master-Pr체fung des Studiengangs Angewandte Informatik an der Ruhr-Universit채t Bochum\par}
        \vspace{1em}
        vorgelegt von\par
        \vspace{2em}
        Leonard Papenmeier\par 108017257755\par
        \vspace{2em}
        01.01.1980\par

        \vfill
        Prof. Dr. Laurenz Wiskott\par
        M.Sc. Zahra Fayyaz


    \end{titlepage}
    \pagenumbering{Roman}
    \tableofcontents
    \newpage
    \setcounter{savepage}{\arabic{page}}
    \pagenumbering{arabic}


    \section{Introduction}\label{sec:introduction}


    \section{Theoretical Background}\label{sec:theoretical-background}
    \include{background}


    \section{Methods}\label{sec:methods}
    \input{methods}


    \section{Results}\label{sec:results}

    \subsection{Visual Features in Variational Autoencoders}\label{subsec:results_visual_features_in_variational_autoencoders}
    The following sections describe the results of the experiments on visual features in variational autoencoders.

    \begin{itemize}
        \item Results non-AlexNet-like-VAE on CelebA: especially layer 1 kernels
        \item Results AlexNet-like-VAE on ImageNet: especially layer 1 kernels
        \item Results AlexNet-like image classification CNN on ImageNet: especially layer 1 kernels
        \item Results AlexNet-like-VAE with frozen decoder from classification network
    \end{itemize}

    \subsubsection{AlexNet Image Classification}
    To make sure that the network structure of the \ac{VAE} is apt to generate Gabor wavelets, image classification was performed on ImageNet (see Figure~\ref{fig:alexnet} and Section~\ref{subsec:visual-features-variational-autoencoders} for the used network, see Section~\ref{ssec:imagenet} for ImageNet).
    As the accuracy was not of primary concern, the training was stopped during the tenth epoch (\textbf{If time: train all 100 epochs}), the top-1 training accuracy at this time was at 0.85.

    \begin{figure}
        \centering
        \includegraphics[width=0.9\textwidth]{images/alexnet_classification_l1_kernels.png}
        \caption[Image classification - Layer 1 Kernels]{Convolutional Kernels in the first layer of the image classification network. The filters are shown in their original size (11x11).}
        \label{fig:classification_layer1_kernels}
    \end{figure}

    Figure~\ref{fig:classification_layer1_kernels} shows all 256 convolutional kernels of the image classification network.
    It is easy to see that in many kernels, Gabor wavelet-like filters emerge.

    \subsection{Activity Correlation in \acp{VAE}}\label{subsec:results_activity-correlation-in-vaes}


    \section{Discussion}\label{sec:discussion}

    \subsection{Visual Features in Variational Autoencoders}\label{subsec:discussion_visual_features_in_variational_autoencoders}
    \begin{itemize}
        \item Reconstructions of AlexNet-VAE don't look natural at all, this might be because ImageNet, unlike CelebA, is not properly aligned and contains images from a large variety of classes.
        This might be another hint towards the assumption that \acp{VAE} are no suitable model for semantic representations
        \item How does it come that supervised models seem to be a good representation of \ac{IT} cortical representation~\citep{khaligh2014deep}? Maybe the brain learns in a \say{supervised} manner in the sense that if you have never seen a horse, you need someone to tell you that that is a horse in order to make sense out of it.
        However, you might, at least, be able to recognize that it is an animal.
        Also, if someone tells you \say{This is a horse.}, you'll be able to recognize horses from different orientations and in different body positions without further training.
        This is quite different from how \acp{CNN} capture animals and is a strong hint to that supervised \acp{CNN} alone a no sufficient model for cortical IT representations.
    \end{itemize}


    \section{Conclusion}\label{sec:conclusion}

    \newpage
    \printbibliography

    \newpage
    \pagenumbering{Roman}
    \setcounter{page}{\thesavepage}
    \section*{Acronyms}
    \begin{acronym}[TDMA]
        \acro{VAE}{Variational Autoencoder}
        \acrodefplural{VAE}{Variational Autoencoders}
        \acro{CNN}{Convolutional Neural Network}
        \acrodefplural{CNN}{Convolutional Neural Networks}
        \acro{IT}{Inferior Temporal Cortex}
        \acro{ReLU}{Rectified Linear Unit}
        \acro{LeakyReLU}{Leaky Rectified Linear Unit}
        \acro{ILSVRC2017}{Large Scale Visual Recognition Challenge 2017}
        \acro{MSE}{Mean Squared Error}
    \end{acronym}
    \newpage
    \listoffigures
    \newpage
    \listoftables
    \newpage
    \include{erklaerung}


\end{document}
